{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EAlUrY3uT1e",
        "outputId": "169023e7-b4f6-42c9-c352-0196b5e4d954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 加载数据集\n",
        "categories = None\n",
        "newsgroups_data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "data = pd.DataFrame({'text': newsgroups_data.data, 'label': newsgroups_data.target})\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# 使用 TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# 训练逻辑回归模型使用 Tfidf 特征\n",
        "model_tfidf = LogisticRegression()\n",
        "model_tfidf.fit(X_train_tfidf, y_train)\n",
        "predictions_tfidf = model_tfidf.predict(X_test_tfidf)\n",
        "accuracy_tfidf = accuracy_score(y_test, predictions_tfidf)\n",
        "print('Accuracy with Tfidf: ', accuracy_tfidf)\n",
        "\n",
        "# 文本分词\n",
        "X_train_tokenized = [word_tokenize(text.lower()) for text in X_train]\n",
        "X_test_tokenized = [word_tokenize(text.lower()) for text in X_test]\n",
        "\n",
        "# 训练 Word2Vec 模型\n",
        "w2v_model = Word2Vec(sentences=X_train_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "w2v_model.train(X_train_tokenized, total_examples=len(X_train_tokenized), epochs=10)\n",
        "\n",
        "# 将 Word2Vec 模型的词汇表转换为集合以加快查找速度\n",
        "word_set = set(w2v_model.wv.index_to_key)\n",
        "\n",
        "def document_vector(doc):\n",
        "    doc = [word for word in doc if word in word_set]\n",
        "    return np.mean(w2v_model.wv[doc], axis=0) if doc else np.zeros(100)\n",
        "\n",
        "def compute_document_vectors(docs):\n",
        "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        return list(executor.map(document_vector, docs))\n",
        "\n",
        "X_train_w2v = np.array(compute_document_vectors(X_train_tokenized))\n",
        "X_test_w2v = np.array(compute_document_vectors(X_test_tokenized))\n",
        "\n",
        "model_w2v = LogisticRegression()\n",
        "model_w2v.fit(X_train_w2v, y_train)\n",
        "predictions_w2v = model_w2v.predict(X_test_w2v)\n",
        "accuracy_w2v = accuracy_score(y_test, predictions_w2v)\n",
        "print('Accuracy with Word2Vec: ', accuracy_w2v)\n",
        "\n",
        "# 比较两种方法的性能\n",
        "print('Comparison of Models:')\n",
        "print('TF-IDF Accuracy: ', accuracy_tfidf)\n",
        "print('Word2Vec Accuracy: ', accuracy_w2v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9zLTEoavf-a",
        "outputId": "3aca63da-a48b-49ff-e3a6-39f833bb4f58"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Tfidf:  0.6888594164456233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Word2Vec:  0.5084880636604775\n",
            "Comparison of Models:\n",
            "TF-IDF Accuracy:  0.6888594164456233\n",
            "Word2Vec Accuracy:  0.5084880636604775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    }
  ]
}